{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell-cell interactions arising from somatic contact or paracrine signaling, which can be inferred based on contact or proximity between cells that occurred with higher frequency than by random chance (29, 30). \n",
    "\n",
    "We examined whether these potential cell-cell interactions were cell-type specific. To this end, we only considered cell types at the subclass level and determined the frequency with which cell-cell contacts (or proximity) were observed between two subclasses of cells. \n",
    "\n",
    "Two neighboring cells were considered contacting (or in proximity) if their centroid distance was <15 μm, which is approximately the size of the soma of a single cell in both human and mouse cortex (31). \n",
    "\n",
    "We determined how much this frequency was above random chance and how significant this difference was by comparing the observed contact frequency with the expected contact frequencies from spatial permutations. \n",
    "\n",
    "To avoid artifacts arising from the laminar organization of cells and spatial variation of cells density (namely, cell types in the regions of higher cell density or with similar laminar distributions can result in a higher contact frequency by random chance), we designed our spatial permutations to only disrupt the spatial relationship between neighboring cells while still preserving the laminar distribution and local density of each cell type\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "Fig S10: \n",
    "(A) Schematic of spatial permutation test that determines the significance of interactions between cell types. Two cells were considered contacting if their nucleus centroids were within 15 μm in the imaging plane, which is approximately the size of the cell body of a single neuron. Contact frequency between any two cell types was determined as the observed frequency. Then, spatial localization of each cell was randomized within a radius of 50 μm, unless otherwise mentioned. Expected contact frequency between any two cell types was determined in each permutation and such permutation was performed 1,000 times to obtain the distribution of expected contact frequencies. The significance of observed contact frequency was calculated using one-tailed z-test and P-values were corrected to FDR (false discovery rate) using Benjamini-Hochberg Procedure. \n",
    "(B) Spatial map of L2/3 IT cells in a human MTG slice. (Left) Measured spatial map. (Middle and right) Two example spatial maps after spatial permutations described in (A). \n",
    "(C) Cortical depth distributions of L2/3 IT cells (light blue) and other cells (light red) in the human MTG slice shown in (B). (Left) Measured cortical depth distributions. (Middle and right) Cortical depth distributions after two example spatial permutations described in (A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: \n",
    "- For Each Z plane, for each specimen\n",
    "    - Grab all cells within said plane\n",
    "    - Find all sets of individual cells that are within 15um of one another (maybe go cell by cell? Is there a faster way?)\n",
    "    - group by cell type and calculate observed frequency of cell type - cell type interaction\n",
    "    - randomize spatial location of all cells by 50um and recalculate observed frequency (save two of these)\n",
    "    - do so 1000 times to get a distribution\n",
    "    - calculate one-tailed z-test of observed vs randomized. Benjamini-Hochberg goes here?\n",
    "    - plot spatial map of specific cell types of interest pre randomization and post 2 randomizations (this will probably involve saving two randomizations and creating new h5ad files for them, possibly concatting them together so they can all be cirro doritod)\n",
    "    - plot histogram of cortical depth distro of celltypes of interest vs all other cells pre and post 2 permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import json\n",
    "\n",
    "filepaths = ['/home/imaging_mfish/MERSCOPENAS04_data/human/atlas/merfish_output/202204251522_H1930002Cx58V10200710104_VMSC02501/processed/202204251522_H1930002Cx58V10200710104_VMSC02501.h5ad']\n",
    "cell_h5ad = sp.read_h5ad(filepaths[0]) \n",
    "#obs has class, obsm spatial has location. IDs are matched (so spatial 0 = obs 0)\n",
    "cell_data = cell_h5ad.obs\n",
    "cell_data[['x', 'y']] = cell_h5ad.obsm['spatial']\n",
    "cell_data = cell_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.262702</td>\n",
       "      <td>-6.699267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.911079</td>\n",
       "      <td>-1.495655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.058107</td>\n",
       "      <td>-0.427929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.324733</td>\n",
       "      <td>6.240685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.560013</td>\n",
       "      <td>5.404284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.996235</td>\n",
       "      <td>-5.833533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-7.057645</td>\n",
       "      <td>-0.435488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-7.058519</td>\n",
       "      <td>-0.421081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4.607645</td>\n",
       "      <td>-5.363731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.933284</td>\n",
       "      <td>3.846576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y\n",
       "0    2.262702 -6.699267\n",
       "1   -6.911079 -1.495655\n",
       "2   -7.058107 -0.427929\n",
       "3   -3.324733  6.240685\n",
       "4    4.560013  5.404284\n",
       "..        ...       ...\n",
       "995  3.996235 -5.833533\n",
       "996 -7.057645 -0.435488\n",
       "997 -7.058519 -0.421081\n",
       "998  4.607645 -5.363731\n",
       "999  5.933284  3.846576\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main code here\n",
    "real_data = cell_data.copy()\n",
    "real_dists_df = spatial_distance_calculator(cell_data) #df now\n",
    "real_grouped_interactions = celltype_groupage(real_dists_df, -1, None)\n",
    "real_grouped_interactions.to_csv('real_grouped_obs_freq.csv')\n",
    "# #random 50um circle\n",
    "# theta = np.random.uniform(low=0, high=2*np.pi, size=1000)  # angle\n",
    "# rand_circle_points = pd.DataFrame({'x' : np.sqrt(50) * np.cos(theta), 'y' : np.sqrt(50) * np.sin(theta)})\n",
    "# grouped_interactions = pd.DataFrame(columns=['count', 'root_cell_type', 'int_cell_type', 'obs_freq'])\n",
    "# for rand_point in rand_circle_points:\n",
    "#     # randomize spatial location of all cells within a radius of 50 μm and recalculate observed frequency \n",
    "#     data_copy = real_data.copy()\n",
    "#     randomized_data = data_copy[['x_microns', 'y_microns']] * rand_point[['x', 'y']]\n",
    "#     fake_dists_df = spatial_distance_calculator(randomized_data)\n",
    "#     grouped_interactions.append(celltype_groupage(fake_dists_df, count, grouped_interactions))\n",
    "# grouped_interactions.to_csv('fake_grouped_obs_freq_calcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-193-4842f71afddb>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-193-4842f71afddb>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    dist_df = dist_df['close_dist_idxs'].apply(lambda x: x.remove(values) if dist_df[x.index] in x.values(), axis=1)\u001b[0m\n\u001b[0m                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#def spatial_distance_calculator(cell_data): #convert back to function once fixed\n",
    "    #calculate pairwise distances for entire celldata subset\n",
    "all_dists = pairwise_distances(cell_data[['x', 'y']].to_numpy(), n_jobs=2)\n",
    "dist_df = pd.DataFrame(all_dists, index=cell_data.index.values,columns = cell_data.index.values).where(all_dists <= 15, 0)\n",
    "dist_df['close_dist_idxs'] = dist_df.apply(lambda x: list(dist_df.columns[x!=0]), axis=1)\n",
    "#remove value in close dist idxs if inverse appears elsewhere\n",
    "dist_df = dist_df['close_dist_idxs'].apply(lambda x: x.remove(values) if dist_df[x.index] in x.values(), axis=1) #incorrect! see cell below\n",
    "#combo_df = pd.concat((cell_data, dist_df['close_dist_idxs']), axis=1) \n",
    "# you can just do the observation frequency calculation here! Groupby (some combo of close dist idxs + type), then count.\n",
    "#  return combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2]</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3]</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rel type\n",
       "1     [2]    a\n",
       "2  [1, 3]    b\n",
       "3  [2, 4]    a\n",
       "4     [3]    c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[1, 3]\n",
      "[2, 4]\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "Name: rel, dtype: object"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST CELL TO FIGURE OUT DUPLICATE REMOVAL\n",
    "#test_df[test_df.rel.apply(lambda x: np.intersect1d(x, list(test_df.index)).size > 1)] #works but removes EVERYTHING, not just duplicates\n",
    "#above would work if we could guarantee multiple list items per index, but we cant\n",
    "#\"find value from series where series at that value equals original value index... but then only remove the duplicates!\"\n",
    "test_df = pd.DataFrame({'rel' : [[2], [1, 3], [2, 4], [3]], 'type' : ['a', 'b', 'a', 'c']}, index = [1, 2, 3, 4])\n",
    "display(test_df)\n",
    "def remove_dups(rel_list):\n",
    "    for val in rel_list:\n",
    "        print(rel_list)\n",
    "        idx = test_df[test_df.rel.apply((lambda x: val in x))].index.tolist()[0]\n",
    "        pair_val = test_df.loc[idx, 'rel']\n",
    "        if val in pair_val:\n",
    "            pair_val.remove(val)\n",
    "test_df.rel.apply(lambda x: remove_dups(x)) #cant apply by row becaue axis = 0 returns typeerror due to remove_dups calling a function here. FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# calculate one-tailed z-test of observed vs randomized. \n",
    "# grabbed formula from online math homework site\n",
    "# z = (sample mean – population mean) / [population standard deviation/sqrt(n)]\n",
    "obs_freq_calcs = pd.read_csv('all_grouped_obs_freq_calcs.csv')\n",
    "real_data = obs_freq_calcs[obs_freq_calcs['count']==-1]\n",
    "rand_data = obs_freq_calcs[obs_freq_calcs['count']!=-1]\n",
    "for index, row in real_data.iter_rows():\n",
    "    sample_counts = row['obs_freq'] #not a mean?\n",
    "    rand_counts = rand_data[rand_data['root_cell_type']==row['root_cell_type'] & \n",
    "                                  rand_data['int_cell_type']==row['int_cell_type']].obs_freq.values.tolist()\n",
    "    rand_mean = np.mean(population_counts)\n",
    "    rand_std = np.std(population_counts)\n",
    "    z_score = (sample_counts - rand_mean) / (rand_std/np.sqrt(sample_counts)) #is this right?\n",
    "    real_data.iloc[index, 'z-test_score'] = z_score\n",
    "real_data.to_csv('scored_real_cci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survey_nb",
   "language": "python",
   "name": "survey_nb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
